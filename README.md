# simple-Linear-Regression
Simple linear regression is a powerful tool for understanding the relationship between two variables and making predictions based on that relationship. However, it's important to validate the assumptions of the model and interpret the results carefully to draw meaningful conclusions.

# multiple linear regression
Multiple linear regression is a statistical method used to model the relationship between multiple independent variables (predictors) and a single dependent variable (outcome). It extends simple linear regression, which models the relationship between one independent variable and the dependent variable.

 # Polynomial Regression
 
 *Polynomial regression is a powerful technique for modeling non-linear relationships between variables. Unlike simple linear regression, which fits a straight line to the data,     polynomial regression fits a polynomial function.
 
 *In polynomial regression, we model the relationship between the independent variable(s) and the dependent variable using a polynomial equation of degree n. The general form of a   polynomial regression equation with one independent variable

# SVR(support vector regression)
Support Vector Regression (SVR) is a regression algorithm based on Support Vector Machines (SVM), which is primarily used for classification tasks. However, SVR extends the SVM algorithm to handle regression problems. SVR aims to find a function that approximates the mapping from input variables to the continuous output variable, while also controlling for the errors made during the prediction.

# Decision tree regression
                     [here i given the simple decision tree model which  i used in single dataset getting result will be bad but                              I want to show the plot in graph it will not be pretty i can assure it will be good to see , i will recommend                            this decision tree model should be used in highly dimensional dataset]
  
   Decision tree regression is a supervised machine learning algorithm used for predicting continuous values. It works by recursively partitioning the feature space into smaller regions, fitting a simple model (usually a constant) in each region. At each step, the algorithm chooses the feature and the split point that best separates the data according to some criterion, typically minimizing the variance of the target variable within each region.
